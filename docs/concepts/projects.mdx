---
title: "Projects"
description: "Top-level containers for organizing agents, simulations, and objectives"
---

Projects are the top-level organizational containers in OneRun that group together related agents, simulations, and objectives. They provide a way to organize and manage your AI evaluation work.

## Overview

Every agent, simulation, and objective belongs to a project. Projects help you:
- **Organize related work** - Keep agents and their evaluations together
- **Manage access and permissions** - Control who can work with specific evaluations
- **Track progress** - View all simulations and results for a particular initiative

## How Projects Work

Projects serve as containers that organize all your evaluation work. When you create agents, objectives, or simulations, they're automatically associated with a specific project. This organization helps you:

- **Keep related work together** - All agents and simulations for a specific use case stay organized
- **Manage team access** - Control who can work on different evaluation initiatives  
- **Track evaluation progress** - View all simulations and results for a particular project

## Example Projects

<CardGroup cols={2}>
  <Card title="ACME Corp Production" icon="building">
    Production environment for ACME Corp's live customer service agents and evaluations
  </Card>
  <Card title="ACME Corp Staging" icon="flask">
    Testing environment for new agent versions before production deployment
  </Card>
  <Card title="Marketing Team" icon="megaphone">
    Department-specific project for evaluating marketing chatbots and lead qualification agents
  </Card>
  <Card title="Beta Testing Program" icon="rocket">
    Experimental project for testing new evaluation methodologies and agent capabilities
  </Card>
</CardGroup>

## Best Practices

<Tip>
  Create separate projects for different AI systems or business functions to keep evaluations organized and focused.
</Tip>

<Info>
  Use descriptive project names that clearly identify the AI system or use case being evaluated.
</Info>